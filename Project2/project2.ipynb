{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project II (Newton vs the machine) - Solving the chaotic three-body problem using deep neural networks as part of Chalmers TIF285"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Matthias HÃ¼bl & Linus Stach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Additional imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import models, layers, optimizers, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "TEST_FRACTION = 0.1\n",
    "SEED = 2023\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data, idx):\n",
    "    \"\"\"\n",
    "    Get one training instance from the data set at the index idx. \n",
    "    \n",
    "    The data is assumed to be in an array `data`.\n",
    "    \n",
    "    Args:\n",
    "        idx (int): An integer specifying which of the training example to fetch\n",
    "        \n",
    "    Returns:\n",
    "        x (array): An array of shape (time_steps, 3) which specifies the input to\n",
    "                   the neural network. The first column is the time and the second\n",
    "                   and third columns specify the (x, y) coordinates of the second\n",
    "                   particle. Note that the first particle is always assumed to be\n",
    "                   at (1, 0) and the third particle can be inferred from the first\n",
    "                   and second particle's position.\n",
    "                   \n",
    "        y (array): An array of shape (time_steps, 4) which specifies the output that \n",
    "                   is expected from the neural network.\n",
    "                   \n",
    "                   The first two columns specify the (x, y) coordinates of the first\n",
    "                   particles and the next two columns give the coordinates of the \n",
    "                   second particle for the specified time (length of the columns).\n",
    "                   The third particles position can be inferred from the first\n",
    "                   and second particle's position.\n",
    "    \"\"\"\n",
    "    x = dataset[idx, :, [0,3,4]].T\n",
    "    y = dataset[idx, :, [1,2,3,4]].T\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectories(pred):\n",
    "    \"\"\"\n",
    "    Gets the trajectories from a predicted output pred.\n",
    "    \n",
    "    Args:\n",
    "        pred (array): An array of shape (N, 4) where N is the number of time\n",
    "                      steps. The four columns give the positions of the particles\n",
    "                      1 and 2 for all the time steps.\n",
    "    Returns:\n",
    "        p1, p2, p3 (tuple of arrays): Three arrays of dimensions (N, 2) where N is the number \n",
    "                             of time steps and the two columns for each array give \n",
    "                             the positions of the three particles (p1, p2, p3)\n",
    "    \"\"\"\n",
    "    p1 = pred[:, :2]\n",
    "    p2 = pred[:, 2:]\n",
    "    p3 = -p1-p2\n",
    "    return p1, p2, p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectories(p1, p2, p3, ax=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Plots trajectories for points p1, p2, p3\n",
    "    \n",
    "    Args:\n",
    "        p1, p2, p3 (array): Three arrays each of shape (n, 2) where n is the number\n",
    "                            of time steps. Each array is the (x, y) position for the\n",
    "                            particles\n",
    "        ax (axis object): Default None, in which case a new axis object is created.\n",
    "        kwargs (dict): Optional keyword arguments for plotting\n",
    "        \n",
    "    Returns:\n",
    "        ax: Axes object\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_TensorSliceDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Linus\\OneDrive\\OneDrive - TUM\\Semester\\CTH 3. Semester\\Learning from data\\lfd-project\\Project2\\project2.ipynb Zelle 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Linus/OneDrive/OneDrive%20-%20TUM/Semester/CTH%203.%20Semester/Learning%20from%20data/lfd-project/Project2/project2.ipynb#Y116sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x, y  \u001b[39m=\u001b[39m get_data(data\u001b[39m=\u001b[39;49mdata, idx\u001b[39m=\u001b[39;49m\u001b[39m123\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Linus/OneDrive/OneDrive%20-%20TUM/Semester/CTH%203.%20Semester/Learning%20from%20data/lfd-project/Project2/project2.ipynb#Y116sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m p1, p2, p3 \u001b[39m=\u001b[39m get_trajectories(y)\n",
      "\u001b[1;32mc:\\Users\\Linus\\OneDrive\\OneDrive - TUM\\Semester\\CTH 3. Semester\\Learning from data\\lfd-project\\Project2\\project2.ipynb Zelle 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Linus/OneDrive/OneDrive%20-%20TUM/Semester/CTH%203.%20Semester/Learning%20from%20data/lfd-project/Project2/project2.ipynb#Y116sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_data\u001b[39m(data, idx):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Linus/OneDrive/OneDrive%20-%20TUM/Semester/CTH%203.%20Semester/Learning%20from%20data/lfd-project/Project2/project2.ipynb#Y116sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Linus/OneDrive/OneDrive%20-%20TUM/Semester/CTH%203.%20Semester/Learning%20from%20data/lfd-project/Project2/project2.ipynb#Y116sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m    Get one training instance from the data set at the index idx. \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Linus/OneDrive/OneDrive%20-%20TUM/Semester/CTH%203.%20Semester/Learning%20from%20data/lfd-project/Project2/project2.ipynb#Y116sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Linus/OneDrive/OneDrive%20-%20TUM/Semester/CTH%203.%20Semester/Learning%20from%20data/lfd-project/Project2/project2.ipynb#Y116sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m                   and second particle's position.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Linus/OneDrive/OneDrive%20-%20TUM/Semester/CTH%203.%20Semester/Learning%20from%20data/lfd-project/Project2/project2.ipynb#Y116sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Linus/OneDrive/OneDrive%20-%20TUM/Semester/CTH%203.%20Semester/Learning%20from%20data/lfd-project/Project2/project2.ipynb#Y116sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     x \u001b[39m=\u001b[39m dataset[idx, :, [\u001b[39m0\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m4\u001b[39;49m]]\u001b[39m.\u001b[39mT\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Linus/OneDrive/OneDrive%20-%20TUM/Semester/CTH%203.%20Semester/Learning%20from%20data/lfd-project/Project2/project2.ipynb#Y116sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     y \u001b[39m=\u001b[39m dataset[idx, :, [\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m]]\u001b[39m.\u001b[39mT\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Linus/OneDrive/OneDrive%20-%20TUM/Semester/CTH%203.%20Semester/Learning%20from%20data/lfd-project/Project2/project2.ipynb#Y116sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x, y\n",
      "\u001b[1;31mTypeError\u001b[0m: '_TensorSliceDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "x, y  = get_data(data=data, idx=123)\n",
    "p1, p2, p3 = get_trajectories(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and load the pre-trained ANN from the paper (see below) and construct your own ANN using the provided data. Compare the complexity (number of trainable parameters) in the pre-trained versus your own ANN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Follow the lead of the demo notebook for using tensorflow / keras (plus see the hints below).\n",
    "* First download and load the data set and the ANN from the paper (both available on the Canvas course page. Navigate to Files > Project2; see hint below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 1000, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load and unpack a compressed npy array\n",
    "load_data = np.load('data_project2.npz')\n",
    "data = load_data['arr_0']\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset interpretation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape : (9000, 1000, 9)\n",
    "    \n",
    "- 9000 samples\n",
    "- 1000 time steps 0->0.003->3.9\n",
    "- 9: $[t, x_1, y_1, x_2, y_2, v_{x,1}, v_{y,1}, v_{x,2}, v_{y,2}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[:, :, [0,3,4]]\n",
    "y = data[:, :, 1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, some of the trajectories contain collisions such that the positions of the particles get stuck at (0, 0). Check the data to find those trajectories and remove them before training your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=TEST_FRACTION, random_state=SEED)\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(SEED).batch(BATCH_SIZE)\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((X_test, y_test)).shuffle(SEED).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define own model, loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Sequential MLP network\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='softmax')])\n",
    "\n",
    "# Define adam optimizer\n",
    "optimizer = optimizers.Adam(0.001, 0.5, 0.5)\n",
    "\n",
    "# Define MAE loss\n",
    "loss = losses.MeanAbsoluteError()\n",
    "\n",
    "# Compile our model\n",
    "model.compile(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, epochs=EPOCHS, validation_data = val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get provided model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = keras.models.load_model(\"Breen_NN_project2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test provided model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pre_trained_model.predict(get_data(data, idx=123)[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the Mean Absolute Error (MAE) vs epoch from the training of your own ANN (as in Fig. 3 of the paper). I.e. you should show both the MAE metric on the training and the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the accuracy of the pre-trained ANN by showing some trajectories and the ANN prediction as in Fig. 4 of the paper. Add also the trajectory of your ANN and comment on its performance. (Note that you should not expect your own ANN to perform as well as the pre-trained one. In addition, the trajectories that are shown in the paper seem to be ones for which the model works very well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the computational cost of making a prediction with the ANN. You will find that it is much shorter than the numerical integration performed by `Brutus` (which according to the reference takes minutes to hours for finding a trajectory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having access to these ANN emulators you can explore the chaotic aspect of this motion by creating a hundred different trajectories from a slightly disturbed initial condition. Try to reproduce Fig. 5 in the paper (both with the pre-trained and your own ANN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a helper function that extracts the velocity at each time step.\n",
    "* Compute the potential energy and the kinetic energy at each time step. The units are chosen such that the total energy is just the sum of these two.\n",
    "* Check for the conservation of energy in: (i) the data generated by `Brutus` (note that the velocities are given in the last few columns of the data file); (ii) the pre-trained model from the paper; (iii) your ANN model.\n",
    "* Create a custom loss function and re-train your model to be trained (constrained) by energy conservation. (Unfortunately, you should not expect any significant improvement in the model with the energy-conserving loss function.)\n",
    "* Reproduce Fig. 6 (with the green line being replaced by your energy-conserving ANN). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
